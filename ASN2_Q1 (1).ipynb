{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvP59FO7DOB3",
        "outputId": "8ad3f39b-1e71-4013-e1a0-e77813c87330"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def simple_qa(question, context, api_token):\n",
        "    \"\"\"\n",
        "    Simple Question-Answering using Hugging Face Inference API\n",
        "\n",
        "    Parameters:\n",
        "    - question (str): The question to ask\n",
        "    - context (str): The context containing the answer\n",
        "    - api_token (str): Your Hugging Face API token\n",
        "\n",
        "    Returns:\n",
        "    - Answer or error message\n",
        "    \"\"\"\n",
        "    url = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
        "    payload = {\n",
        "        \"inputs\": {\n",
        "            \"question\": question,\n",
        "            \"context\": context\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data.get('answer', 'No answer found.')\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    api_token = \"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\"  # Replace with your token\n",
        "    context = \"Hugging Face is a company that provides machine learning tools and models.\"\n",
        "    question = \"What does Hugging Face provide?\"\n",
        "\n",
        "    answer = simple_qa(question, context, api_token)\n",
        "    print(f\"Q: {question}\\nA: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sjBM9qRDPKu",
        "outputId": "77e18990-458d-4826-959f-1074516bb750"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What does Hugging Face provide?\n",
            "A: machine learning tools and models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcN95YmHb-u",
        "outputId": "561517d6-5494-4f2b-b7ae-0221c3d129a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "# Install the transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the huggingface_hub library\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQAxONpmHpfr",
        "outputId": "a0131c8c-b762-4f92-bfdf-fd24ca678b64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries: InferenceClient for interacting with Hugging Face models,\n",
        "# getpass for securely getting input, and textwrap for formatting output text.\n",
        "from huggingface_hub import InferenceClient\n",
        "from getpass import getpass\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "5H6l8HloHyGw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cidcNKSaIMPZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Hugging Face API token securely using getpass.\n",
        "# This prevents the token from being displayed in the notebook output.\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to get HF_TOKEN from Colab secrets:\", e)\n",
        "    HF_TOKEN = None\n",
        "\n",
        "\n",
        "if HF_TOKEN is None:\n",
        "    HF_TOKEN = getpass(\"token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk1KJ6oOH39w",
        "outputId": "e7165d76-fe9f-416e-f725-fb0c847ef20d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed to get HF_TOKEN from Colab secrets: Secret HF_TOKEN does not exist.\n",
            "token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the InferenceClient with the specified model (\"HuggingFaceH4/zephyr-7b-alpha\")\n",
        "# and provide the Hugging Face token for authentication.\n",
        "client=InferenceClient(\"HuggingFaceH4/zephyr-7b-alpha\",token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "Gqea89NAIjRd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to enter a question and store it in the user_question variable.\n",
        "user_question =input(\"Enter your question: \")\n",
        "# Create a list of messages to send to the model.\n",
        "# This includes a system message defining the assistant's role and the user's question.\n",
        "messages=[{\"role\": \"system\",\"content\":\"You are a helpful and knowledgeable assistant\"},{\n",
        "    \"role\": \"user\",\"content\":user_question\n",
        "}]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZJbSUKRIxfJ",
        "outputId": "2ad8e3b4-e2e7-459c-eae3-7ca09da23ba5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your question: what is otp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the messages to the Hugging Face model using the chat_completion method\n",
        "# and store the response in the 'response' variable.\n",
        "# max_tokens limits the length of the generated response.\n",
        "response=client.chat_completion(messages=messages,max_tokens=200)"
      ],
      "metadata": {
        "id": "oFTWkDTjIzty"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a newline and the word \"answer\" to the output.\n",
        "print(\"\\nanswer\")\n",
        "# Format and print the model's response.\n",
        "# textwrap.fill wraps the text to a specified width (80 characters).\n",
        "# response.choices[0].message.content.strip() accesses the content of the response\n",
        "# and removes leading/trailing whitespace.\n",
        "print(textwrap.fill(response.choices[0].message.content.strip(),width=80))"
      ],
      "metadata": {
        "id": "NwBJywF5I2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b8fa389-dd1a-4048-b734-ca5f53780c39"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "answer\n",
            "OTP stands for One Time Password or One Time PIN. It is a temporary, unique code\n",
            "or number that is valid for a single login or transaction. This code is sent to\n",
            "the user's registered phone number or email as an additional verification method\n",
            "for security purposes while logging into their account or making a transaction\n",
            "for a one-time activity. OTP or one-time password can be set up by the user as\n",
            "an extra layer of security, to ensure only authorized users can log in or access\n",
            "their data. OTP is generated dynamically and cannot be reused again for that\n",
            "specific session or activity. This extra layer of security is used to prevent\n",
            "unauthorized access and mitigates the risks of cyber attacks against login\n",
            "credentials being compromised. It is commonly used in online banking,\n",
            "e-commerce, and other online services for authentication purposes. OTPs are also\n",
            "useful for troubleshooting and resetting passwords as a way of recovering lost\n",
            "access, or in case\n"
          ]
        }
      ]
    }
  ]
}