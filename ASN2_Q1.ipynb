{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvP59FO7DOB3",
        "outputId": "0f15bb12-2401-4635-e51e-e4652abbeee1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def simple_qa(question, context, api_token):\n",
        "    \"\"\"\n",
        "    Simple Question-Answering using Hugging Face Inference API\n",
        "\n",
        "    Parameters:\n",
        "    - question (str): The question to ask\n",
        "    - context (str): The context containing the answer\n",
        "    - api_token (str): Your Hugging Face API token\n",
        "\n",
        "    Returns:\n",
        "    - Answer or error message\n",
        "    \"\"\"\n",
        "    url = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"\n",
        "    headers = {\"Authorization\": f\"Bearer {api_token}\"}\n",
        "    payload = {\n",
        "        \"inputs\": {\n",
        "            \"question\": question,\n",
        "            \"context\": context\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        return data.get('answer', 'No answer found.')\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    api_token = \"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\"  # Replace with your token\n",
        "    context = \"Hugging Face is a company that provides machine learning tools and models.\"\n",
        "    question = \"What does Hugging Face provide?\"\n",
        "\n",
        "    answer = simple_qa(question, context, api_token)\n",
        "    print(f\"Q: {question}\\nA: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sjBM9qRDPKu",
        "outputId": "05297d99-4fb2-4861-b4d1-5cd550f80b1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: What does Hugging Face provide?\n",
            "A: machine learning tools and models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcN95YmHb-u",
        "outputId": "a8e58003-b894-41d4-a4ab-0c1956dd60d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ],
      "source": [
        "# Install the transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the huggingface_hub library\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQAxONpmHpfr",
        "outputId": "caa8a059-8914-40f1-8b1b-260937488083"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries: InferenceClient for interacting with Hugging Face models,\n",
        "# getpass for securely getting input, and textwrap for formatting output text.\n",
        "from huggingface_hub import InferenceClient\n",
        "from getpass import getpass\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "5H6l8HloHyGw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cidcNKSaIMPZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Hugging Face API token securely using getpass.\n",
        "# This prevents the token from being displayed in the notebook output.\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "except Exception as e:\n",
        "    print(\"Failed to get HF_TOKEN from Colab secrets:\", e)\n",
        "    HF_TOKEN = None\n",
        "\n",
        "\n",
        "if HF_TOKEN is None:\n",
        "    HF_TOKEN = getpass(\"token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk1KJ6oOH39w",
        "outputId": "67636d16-4400-4737-cad9-c67b854566b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to get HF_TOKEN from Colab secrets: Secret HF_TOKEN does not exist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the InferenceClient with the specified model (\"HuggingFaceH4/zephyr-7b-alpha\")\n",
        "# and provide the Hugging Face token for authentication.\n",
        "client=InferenceClient(\"HuggingFaceH4/zephyr-7b-alpha\",token=HF_TOKEN)"
      ],
      "metadata": {
        "id": "Gqea89NAIjRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to enter a question and store it in the user_question variable.\n",
        "user_question =input(\"Enter your question: \")\n",
        "# Create a list of messages to send to the model.\n",
        "# This includes a system message defining the assistant's role and the user's question.\n",
        "messages=[{\"role\": \"system\",\"content\":\"You are a helpful and knowledgeable assistant\"},{\n",
        "    \"role\": \"user\",\"content\":user_question\n",
        "}]"
      ],
      "metadata": {
        "id": "lZJbSUKRIxfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Send the messages to the Hugging Face model using the chat_completion method\n",
        "# and store the response in the 'response' variable.\n",
        "# max_tokens limits the length of the generated response.\n",
        "response=client.chat_completion(messages=messages,max_tokens=200)"
      ],
      "metadata": {
        "id": "oFTWkDTjIzty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a newline and the word \"answer\" to the output.\n",
        "print(\"\\nanswer\")\n",
        "# Format and print the model's response.\n",
        "# textwrap.fill wraps the text to a specified width (80 characters).\n",
        "# response.choices[0].message.content.strip() accesses the content of the response\n",
        "# and removes leading/trailing whitespace.\n",
        "print(textwrap.fill(response.choices[0].message.content.strip(),width=80))"
      ],
      "metadata": {
        "id": "NwBJywF5I2kD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}