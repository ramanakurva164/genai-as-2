{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCUX087/lL7fcMLOAvNgLO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramanakurva164/genai-as-2/blob/main/ASN2_QNA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grmQrwVA319_",
        "outputId": "9675aba7-bd4a-4b58-ea28-6264ceae009d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv3doLPJ3rYZ",
        "outputId": "5048511e-06ab-42a7-f0be-186427e2c28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Story generated with temperature=0.3 ---\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a distant kingdom, the king of kings was called King. He had been given power over all things and he would rule for ever until his death at last (Genesis 1:8).\n",
            "The first thing you notice about this story is that it's very much like what happened to Jesus Christ when God gave him authority on earth during His earthly ministry as an adult man who lived through many trials before finally being able go back into heaven after dying from sin because we were too young or not yet fully mature enough to be saved by Him? And then there are some interesting parallels between these two stories which I will try to explain below but if anyone has any questions please let me know!\n",
            "\n",
            "--- Story generated with temperature=0.7 ---\n",
            "\n",
            "Once upon a time in a distant kingdom, the world was full of men who were proud and brave. Some looked like princes or noblemen; others had bright eyes—they wore their royal robes to honour themselves for good deeds: they never made anyone afraid at all! But there could be no such thing as an emperor without courage… For these knights are not heroes but merely soldiers.\"\n",
            "\"Then you must die,\" said Prince Leyshenne with great seriousness from his seat on this table behind him. \"You have become king by your own hand? Then what does that matter?\"\n",
            "The King's face hardened even more when he saw how well-heeled both nobles and young people took up arms against one another after receiving news about Qin Yu having been captured during World War I alone.[11] In fact it seemed only if Han Qian Meng heard any rumor among those two groups before giving them orders is she willing so badly suited for her position amongst rulers above herself because everyone knew better than\n",
            "\n",
            "--- Story generated with temperature=1.0 ---\n",
            "\n",
            "Once upon a time in a distant kingdom, the queen sent her son to his grave. After they had found their lost prince's head resting on one of many ancient shrines she told him that he was dead and all would be given back by them for it as well . She also mentioned how while at sea I saw such things from heaven with no ill will but through my god.\" A man who visited this house said when there were three brothers buried under stones over which none could see anyone besides each other now living (NIV), what should come next? So God left two sons; first before returning home after visiting relatives about four centuries old: second even younger brother only 2 years older than himself or more!\n",
            "So just like any great prophet comes across some terrible thing happening during an event... why go around telling those same people exactly nothing different?! What else does every preacher tell us if our own ignorance is behind everything we do ? Well today most religious scholars simply refuse to give credence whatsoever\n",
            "\n",
            "--- Story generated with temperature=1.3 ---\n",
            "\n",
            "Once upon a time in a distant kingdom, the king himself came to that city; where he laid his hand on their neck-sleeves and prayed for them. As soon as this was done they began weeping bitterly through sorrow of not finding Him again.' That evening Mary did bear out what all Christians think Jesus should do unto each other.\"—De Trin., vi xlii The \"vulgarly\" prayer at Pentecost is described later with reference both inside Church sources (\"Fidela: 1832\"), after its author (the Archbishop Peter) makes an entry entitled \"'The Resurrection,\" which indicates there were times when one or more disciples from Jerusalem found St Paul dying violently about 3 feet off His chest by chance during Saint Clement I's preaching…\" In short, it appears only among men who have become monks can be considered martyrdom since those people are often forced underground under pretext that someone has sacrificed themselves while sitting quietly next To die could well cause 'sinful' conduct towards\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "def generate_story(prompt, temperature=0.7):\n",
        "    \"\"\"\n",
        "    Generates a story continuation based on the given prompt using GPT-2.\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): The starting text prompt for the story\n",
        "    - temperature (float): Sampling temperature for diversity (default = 0.7)\n",
        "\n",
        "    Returns:\n",
        "    - generated_text (str): The generated story continuation\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load pre-trained GPT2 tokenizer and model\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "        # Encode input prompt\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "        # Generate output with sampling parameters\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            do_sample=True,               # Enable sampling\n",
        "            temperature=temperature,      # Sampling temperature\n",
        "            top_k=50,                     # Top-K sampling\n",
        "            top_p=0.95,                   # Nucleus sampling (Top-P)\n",
        "            max_length=200,               # Max output length\n",
        "            repetition_penalty=1.2,       # Penalty to reduce repetition\n",
        "            pad_token_id=tokenizer.eos_token_id  # Padding token\n",
        "        )\n",
        "\n",
        "        # Decode and return generated text\n",
        "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Exception handling with error message\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Test cases with different temperatures\n",
        "test_prompt = input(\"..\")\n",
        "# \"Once upon a time in a distant kingdom,\"\n",
        "temperatures = [0.3, 0.7, 1.0, 1.3]\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"\\n--- Story generated with temperature={temp} ---\\n\")\n",
        "    story = generate_story(test_prompt, temperature=temp)\n",
        "    if story:\n",
        "        print(story)\n",
        "    else:\n",
        "        print(\"Failed to generate story.\")"
      ]
    }
  ]
}